I have been trying to gather information about ML, AI research in India, especially at IITs and IISc. From a recent post on LinkedIn by Prof Smruti Sarangi, it appears that at least 80% of current Ph. D. aspirants are pursuing research in ML and AI. Until 2000, PhDs in Soft Computing were mostly from ISI Kolkata. I believe ISI at that time produced about 10-15 odd Ph. Ds. IITs looked for people in core areas of computer science. If I am not mistaken, very few soft computing specialists feature CS faculty at IITs or IISc. One of our senior colleagues once remarked that ISI Ph. Ds are good researchers and published a lot. However, their research is too unidimensional for a CS dept at IITs. I am not sure if he may want to revise his opinion about the recent stream of Ph. Ds from IITs with 80% is ML, AI, and Data Science.
I fully concur with Prof Sarangi's observations about candidates' knowledge in the core areas of computer science and Engineering. I have interviewed many candidates in various selection committees; not even 10% have a basic understanding of programming and algorithms. In fact, in one of the selection committees at an NIT, one of the panelists dared to ask a candidate to write a print hello program in C. I was astonished and asked the said panelist in an inaudible voice: "Are you serious?". She was very confident and replied in an equally inaudible voice: "Just wait and see." One other independent panel member (I believe a Prof in mechanical engineering from IITB) was curiously watching our exchanges. The candidate did not have any clue of C programming though he claimed to have written programs in C for his dissertation. After the candidate went out, the panel member from IITB told me that he knew that the lady panelist would be right. Now it seems IITs and IISc have joined the stream.
 Forget network, database, computer architecture, compilers or OS, the candidates don't even have good background on fundamentals like DS, Algorithms, and Discrete Structures.
I will add Data Science to ML-AI craze. Data scientists are "Statisticians masquerading as computer programmers" or "Programmers masquerading as statisticians". However, I believe some of the readers' reactions to Prof Sarangi's post may be valid on the surface. One guy from some industry (possibly from the gaming and entertainment business) comments that AI and ML provide a higher order of abstractions that can aid in more complex problem-solving. He cites the complexity of ray tracing in discovering gaming alternatives that AI can easily do. He also says that mechanical engineers biologists need not understand the intricacies of neural networks to solve their problems. But the question that remains unanswered is:
How does the mechanical engineer or the biologist even know that the solution is correct?
If none of them are trained in their core competence, they will also lack the ability to judge a solution. So the real risk of AI is not in super intelligent machines controlling humans but in machines that are not smart enough to perform the tasks that humans give them. The other side of the spectrum is that humans turn dumb when they think some software tools could make smarter decisions on their behalf.
 MATLAB is one such example. Power and controls engineers use MATLAB a lot. But a solid understanding of the core is required to use the tools intelligently. Possibly, those who have a different point of view have not been able to get to the bottom of the central theme of Prof Sarangi's post. He is no ameture in the area of AI-ML. He does have high regard for ML and AI techniques. Like him, many other researchers also use AI and techniques based on heuristics and learning for their research.
David L. Parans, Prof Emeritus of McMaster University, published a note on "Real Risk of AI". He had early training in AI as a student from Professors who were pioneers in AI research. He says that AI relied more on intuitions than a disciplined approach to physics, mathematics, or engineering problem-solving. In a disciplined approach, a problem is thoroughly analyzed, mathematics and physics behind the problem is unraveled, the solutions are often hand simulated and verified using assertion-based model checkers. He says that his Professors at CMU were "clever but had the cavalier attitude" to specific questions and recommended the students to "try and fix it". The foundation of AI research is based on mimicking human intuition and problem solving through heuristics. However, a heuristics works if it is used to select one from possible alternatives or to determine presentation order. More frequently, heuristics are used for speeding up the searching of solution space by applying intelligent pruning and feasibility measures. In other situations, heuristics are untrustworthy. Though Prof Sarangi's post is a bit blunt to the taste of AI and ML enthusiasts, David Pranas puts the same thing using "higher order of abstractions". He states that there are three different ways of AI research:
Building programs that imitate human behavior to understand human thinking;
Building programs that play games well; and
Showing that practical computerized products can use the methods that humans use.
The first one tries to model the human brain where certain elements are unexplained (not understood) and duplicated as black boxes. Parnas recognizes that 
"writing game-playing programs is harmless and builds capabilities". However, it may be dangerous if practical products mimic human methods. He cites the 
example of Captch based recognitions because the character recognition has not been solved programmatically. The programs that imitate human intuitions are 
not always the best way of problem-solving with computers. Imitating human intuition could make programs untrustworthy and dangerous. He gives examples to 
conclude that his impressions about AI techniques are old; however, the lessons they taught him are relevant today.
One may ask: how has it destroyed engineering education in general and CSE in particular? The problem lies in how the lessons are conducted. If teachers 
have not written much of the code themselves, their  expectations from the students would also be low. Many faculty members who teach Data Structure 
courses rely on theory and complexity analysis and do not give programming assignments. The other problem in checking programming assignments is an arduous 
task. Rampant copies from Internet sources make assignments useless. I used MOSS code checker and found that about 30-35% of students indulge in copying. 
It becomes a serious problem to deal with the copies. Most students deny their involvement in copying or assisting friends to copy. The explanations were 
as crazy as that guy was sitting behind me and memorized the entire code of 500 lines. Sometimes, the problem goes down to acute interpersonal bickerings 
among TAs and students. Quite obviously, no one likes to be a part of it. So, the alternative is not to bother about checking assignments.
Someone writes that an average CS UG student at IITs does write 50k lines of code before graduating out. Probably, he must be talking about the situation 
twenty-five years back, when Internet resources were not available that easily. We used to give rigorous programming practice to the undergraduate 
students. The class size used to be small. Cheating in assignments was easily detectable. An average UG student may write about 25-30K lines of C code if 
not more. Most system courses like OS, Databases, Networks, Compilers would require each student to write in an average of 10k lines of C code. Even in the 
Data Structures course, one would typically do a project that often required 5-7k lines. It is not true these days. I remember spending two semesters at 
one of the older IITs where I taught Design of Algorithms in one semester. I asked the students to write programs for a hypothetical coin game and test 
their strategies by conducting tournaments among the program creators. We had a program to play out one student's program against the other. The idea was 
to train the students in discovering better strategies in a competitive environment. The entire class refused to take part in the tournament-based 
assignment. One of the primary arguments was that it would vitiate the camaraderie among batch mates.
As Internet resources became widely available, most students resorted to copying and pasting approaches to problem-solving. I used MOSS to check copying by 
downloading codes from Geeks for Geeks, Programiz, and many other sites and including them as assignments. Invariably 30% of the students who submitted the 
assignments copied, and about 15% did not even bother to submit assignments. They estimated that the time spent in coding could pay off better if they only 
worked for their exams. I noticed a comment on Prof Sarangi's post that IIT graduates 25 years back used to write 50k lines of code on average. Someone 
else says that it is stupid to ask a Ph. D. student how many lines of code he has written. I am not sure if many of these readers are in time wraps. Most 
of them are successful today because they received training 20-25 years back. The only trick that works today is an element of surprise. For example, we 
used a WhatsApp-based exam for remote conduct of exam. We created a protocol full of surprises for students at the beginning of COVID-19 lockdown. 
Therefore, the performance did not vary compared to their previous performance in proctored offline exams. Now I understand that students use two computers 
simultaneously to search for a solution and one for sending the solution. Thinking and learning go to the basics of understanding.
It is an unfortunate craze promoted by industry honchos to create fissures in the foundations of engineering education. I am not sure if short-term gains 
or AI only drives industries; ML and Data Science can propel industry 4.0.
